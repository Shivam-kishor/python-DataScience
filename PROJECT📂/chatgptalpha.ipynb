{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link, please check your internet connection.\n"
     ]
    }
   ],
   "source": [
    "#spyder file\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "start_sequence=\"\\nAI:\"\n",
    "restart_sequence=\"\\nHuman:\"\n",
    "\n",
    "prompt=\"ASK HERE✍️✍️)\"\n",
    "\n",
    "#FUNCTION 1\n",
    "\"\"\"\"prompt\": The text prompt that the model will use to generate a response.\n",
    "\"model\": The name of the OpenAI model that will be used for the text completion. In this case, the model is \"text-davinci-003,\" which is a highly capable and versatile model that can perform a wide range of language tasks.\n",
    "\"temperature\": A value that controls the randomness of the generated text. A lower temperature value will result in more conservative and predictable responses, while a higher temperature value will produce more creative and unexpected responses.\n",
    "\"max_tokens\": The maximum number of tokens (i.e., words or symbols) that the model will generate in the response.\n",
    "\"top_p\": A probability value that controls the diversity of the generated text. A higher top_p value will result in a wider range of possible responses.\n",
    "\"frequency_penalty\": A penalty applied to the model's likelihood estimates for high-frequency words. Increasing this value will make the model less likely to use common words.\n",
    "\"presence_penalty\": A penalty applied to the model's likelihood estimates for repeated words. Increasing this value will make the model less likely to repeat words in the response.\n",
    "\"stop\": A list of strings that the model will use as stopping criteria for the text completion. In this case, the model will stop generating text once it encounters either \"Human:\" or \"AI:\" in the generated response.\"\"\"\n",
    "def openai_create(prompt):\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.9,\n",
    "    max_tokens=150,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0.6,\n",
    "    stop=[\"Human:\", \"AI:\"]\n",
    ")\n",
    "    return response.choices[0].text # type: ignore\n",
    "\n",
    "#FUNCTION 2\n",
    "#To work well gradio\n",
    "def chatgpt_clone(input,history):\n",
    "    history=history or []\n",
    "    s=list(sum(history,()))\n",
    "    s.append(input)\n",
    "    inp=''.join(s)\n",
    "    output=openai_create(inp)\n",
    "    history.append((input,output))\n",
    "    return history,history   \n",
    "\n",
    "#FUNCTION 3\n",
    "def lock(text):\n",
    "    return openai_create,chatgpt_clone\n",
    "demo = gr.Interface(lock, \"text\", \"text\")\n",
    "\n",
    "\n",
    "block=gr.Blocks()\n",
    "\n",
    "with block:\n",
    "    gr.Markdown(\"\"\"<h1><center><marquee><font face=\"comic sans\">\"CHAT_GPT CLONE\"</font></center></h1>\"\"\")\n",
    "    chatbot=gr.Chatbot()\n",
    "    message=gr.Textbox(placeholder=prompt)\n",
    "    state=gr.State()   \n",
    "    submit=gr.Button(\"SEND\")\n",
    "    submit.click(chatgpt_clone, inputs=[message,state], outputs=[chatbot, state])\n",
    "    \n",
    "\n",
    "#Launches a simple web server that serves the demo. Can also be used to create a public link used by anyone to access the demo from their browser by setting share=True.\n",
    "\n",
    "block.launch(share=True, auth=(\"shivam\", \"ppl@123\"),debug=True,show_api=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
